{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchFile='/home/srajaram/preference_videos/humanlabels/hopper-medium-expert-v2/batch_numq100_len998_s3407.pkl'\n",
    "# with open(batchFile, 'rb') as f:\n",
    "#     batchDataset = pickle.load(f)\n",
    "\n",
    "# batchFile='/home/srajaram/preference_videos/humanlabels/hopper-medium-expert-v2/batch_numq100_len100_s3407.pkl'\n",
    "# with open(batchFile, 'rb') as f:\n",
    "#     dataset = pickle.load(f)\n",
    "\n",
    "batchFile='/home/srajaram/preference_videos/humanlabels/hopper-medium-replay-v2/batch_numq500_len100_s3407.pkl'\n",
    "with open(batchFile, 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "# batchFile='/home/srajaram/preference_videos/test/hopper-medium-expert-v2/batch_numq10_len400_s3407.pkl'\n",
    "# with open(batchFile, 'rb') as f:\n",
    "#     longqueries = pickle.load(f)\n",
    "\n",
    "# batchFile='/home/srajaram/preference_videos/testCorr/hopper-medium-expert-v2/batch_numq10_len400_s3407.pkl'\n",
    "# with open(batchFile, 'rb') as f:\n",
    "#     longqueriesCorr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand Query Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########IMPORTED LOCALLY############\n",
      "######REGISTERING ENVIRONMENTS#####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import gym\n",
    "import imageio\n",
    "import jax\n",
    "import numpy as np\n",
    "from absl import app, flags\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import d4rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def qlearning_mujoco_dataset(env, dataset=None, terminate_on_end=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns datasets formatted for use by standard Q-learning algorithms,\n",
    "    with observations, actions, next_observations, rewards, and a terminal\n",
    "    flag.\n",
    "    Args:\n",
    "        env: An OfflineEnv object.\n",
    "        dataset: An optional dataset to pass in for processing. If None,\n",
    "            the dataset will default to env.get_dataset()\n",
    "        terminate_on_end (bool): Set done=True on the last timestep\n",
    "            in a trajectory. Default is False, and will discard the\n",
    "            last timestep in each trajectory.\n",
    "        **kwargs: Arguments to pass to env.get_dataset().\n",
    "    Returns:\n",
    "        A dictionary containing keys:\n",
    "            observations: An N x dim_obs array of observations.\n",
    "            actions: An N x dim_action array of actions.\n",
    "            next_observations: An N x dim_obs array of next observations.\n",
    "            rewards: An N-dim float array of rewards.\n",
    "            terminals: An N-dim boolean array of \"done\" or episode termination flags.\n",
    "    \"\"\"\n",
    "    if dataset is None:\n",
    "        dataset = env.get_dataset(**kwargs)\n",
    "\n",
    "    N = dataset[\"rewards\"].shape[0]\n",
    "    obs_ = []\n",
    "    next_obs_ = []\n",
    "    action_ = []\n",
    "    reward_ = []\n",
    "    done_ = []\n",
    "    xy_ = []\n",
    "    done_bef_ = []\n",
    "\n",
    "    qpos_ = []\n",
    "    qvel_ = []\n",
    "\n",
    "    # The newer version of the dataset adds an explicit\n",
    "    # timeouts field. Keep old method for backwards compatability.\n",
    "    use_timeouts = False\n",
    "    if \"timeouts\" in dataset:\n",
    "        use_timeouts = True\n",
    "\n",
    "    episode_step = 0\n",
    "    for i in range(N - 1):\n",
    "        obs = dataset[\"observations\"][i].astype(np.float32)\n",
    "        new_obs = dataset[\"observations\"][i + 1].astype(np.float32)\n",
    "        action = dataset[\"actions\"][i].astype(np.float32)\n",
    "        reward = dataset[\"rewards\"][i].astype(np.float32)\n",
    "        done_bool = bool(dataset[\"terminals\"][i]) or episode_step == env._max_episode_steps - 1\n",
    "        xy = dataset[\"infos/qpos\"][i][:2].astype(np.float32)\n",
    "\n",
    "        qpos = dataset[\"infos/qpos\"][i]\n",
    "        qvel = dataset[\"infos/qvel\"][i]\n",
    "\n",
    "        if use_timeouts:\n",
    "            final_timestep = dataset[\"timeouts\"][i]\n",
    "            next_final_timestep = dataset[\"timeouts\"][i + 1]\n",
    "        else:\n",
    "            final_timestep = episode_step == env._max_episode_steps - 1\n",
    "            next_final_timestep = episode_step == env._max_episode_steps - 2\n",
    "\n",
    "        done_bef = bool(next_final_timestep)\n",
    "\n",
    "        if (not terminate_on_end) and final_timestep:\n",
    "            # Skip this transition and don't apply terminals on the last step of an episode\n",
    "            episode_step = 0\n",
    "            continue\n",
    "        if done_bool or final_timestep:\n",
    "            episode_step = 0\n",
    "\n",
    "        obs_.append(obs)\n",
    "        next_obs_.append(new_obs)\n",
    "        action_.append(action)\n",
    "        reward_.append(reward)\n",
    "        done_.append(done_bool)\n",
    "        xy_.append(xy)\n",
    "        done_bef_.append(done_bef)\n",
    "\n",
    "        qpos_.append(qpos)\n",
    "        qvel_.append(qvel)\n",
    "        episode_step += 1\n",
    "\n",
    "    return {\n",
    "        \"observations\": np.array(obs_),\n",
    "        \"actions\": np.array(action_),\n",
    "        \"next_observations\": np.array(next_obs_),\n",
    "        \"rewards\": np.array(reward_),\n",
    "        \"terminals\": np.array(done_),\n",
    "        \"xys\": np.array(xy_),\n",
    "        \"dones_bef\": np.array(done_bef_),\n",
    "        \"qposes\": np.array(qpos_),\n",
    "        \"qvels\": np.array(qvel_),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(env, seed):\n",
    "    np.random.seed(seed)\n",
    "    env.seed(seed)\n",
    "    env.observation_space.seed(seed)\n",
    "    env.action_space.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_path='/home/srajaram/PreferenceTransformer/human_label/'\n",
    "env_name='hopper-medium-expert-v2'\n",
    "base_path = os.path.join(query_path, env_name)\n",
    "human_indices_2_file, human_indices_1_file, label_file = sorted(os.listdir(base_path))\n",
    "with open(os.path.join(base_path, human_indices_1_file), \"rb\") as fp:   # Unpickling\n",
    "    human_indices = pickle.load(fp)\n",
    "with open(os.path.join(base_path, human_indices_2_file), \"rb\") as fp:   # Unpickling\n",
    "    human_indices_2 = pickle.load(fp)\n",
    "with open(os.path.join(base_path, label_file), \"rb\") as fp:   # Unpickling\n",
    "    human_labels = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srajaram/.local/lib/python3.10/site-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/home/srajaram/.local/lib/python3.10/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "  deprecation(\n",
      "load datafile: 100%|██████████| 9/9 [00:03<00:00,  2.85it/s]\n"
     ]
    }
   ],
   "source": [
    "saved_indices=[human_indices, human_indices_2]\n",
    "num_query=10\n",
    "saved_labels=human_labels\n",
    "len_query=400\n",
    "seed=3407\n",
    "gym_env = gym.make(env_name)\n",
    "\n",
    "set_seed(gym_env, seed)\n",
    "dataset = qlearning_mujoco_dataset(gym_env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "680608"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_indices[1][90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['observations', 'actions', 'next_observations', 'rewards', 'terminals', 'xys', 'dones_bef', 'qposes', 'qvels'])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get queries from saved indices: 100%|██████████| 10/10 [00:00<00:00, 11834.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "90\n",
      "365443\n",
      "365843\n",
      "#############\n",
      "0\n",
      "90\n",
      "680608\n",
      "681008\n",
      "#############\n",
      "1\n",
      "91\n",
      "455060\n",
      "455460\n",
      "#############\n",
      "1\n",
      "91\n",
      "262910\n",
      "263310\n",
      "#############\n",
      "2\n",
      "92\n",
      "1556756\n",
      "1557156\n",
      "#############\n",
      "2\n",
      "92\n",
      "790404\n",
      "790804\n",
      "#############\n",
      "3\n",
      "93\n",
      "924268\n",
      "924668\n",
      "#############\n",
      "3\n",
      "93\n",
      "741610\n",
      "742010\n",
      "#############\n",
      "4\n",
      "94\n",
      "185003\n",
      "185403\n",
      "#############\n",
      "4\n",
      "94\n",
      "226570\n",
      "226970\n",
      "#############\n",
      "5\n",
      "95\n",
      "1807741\n",
      "1808141\n",
      "#############\n",
      "5\n",
      "95\n",
      "126380\n",
      "126780\n",
      "#############\n",
      "6\n",
      "96\n",
      "184071\n",
      "184471\n",
      "#############\n",
      "6\n",
      "96\n",
      "363840\n",
      "364240\n",
      "#############\n",
      "7\n",
      "97\n",
      "126103\n",
      "126503\n",
      "#############\n",
      "7\n",
      "97\n",
      "823850\n",
      "824250\n",
      "#############\n",
      "8\n",
      "98\n",
      "38993\n",
      "39393\n",
      "#############\n",
      "8\n",
      "98\n",
      "534067\n",
      "534467\n",
      "#############\n",
      "9\n",
      "99\n",
      "924769\n",
      "925169\n",
      "#############\n",
      "9\n",
      "99\n",
      "550661\n",
      "551061\n",
      "#############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query_range = np.arange(len(saved_labels) - num_query, len(saved_labels))\n",
    "for query_count, i in enumerate(tqdm(query_range, desc=\"get queries from saved indices\")):\n",
    "    temp_count = 0\n",
    "    while(temp_count < 2):                \n",
    "        start_idx = saved_indices[temp_count][i]\n",
    "        end_idx = start_idx + len_query\n",
    "\n",
    "        reward_seq = dataset['rewards'][start_idx:end_idx]\n",
    "        obs_seq = dataset['observations'][start_idx:end_idx]\n",
    "        next_obs_seq = dataset['next_observations'][start_idx:end_idx]\n",
    "        act_seq = dataset['actions'][start_idx:end_idx]\n",
    "        timestep_seq = np.arange(1, len_query + 1)\n",
    "\n",
    "        print(query_count)\n",
    "        print(i)\n",
    "        print(start_idx)\n",
    "        print(end_idx)\n",
    "        print(\"#############\")\n",
    "\n",
    "        # if temp_count == 0:\n",
    "        #     total_reward_seq_1[query_count] = reward_seq\n",
    "        #     total_obs_seq_1[query_count] = obs_seq\n",
    "        #     total_next_obs_seq_1[query_count] = next_obs_seq\n",
    "        #     total_act_seq_1[query_count] = act_seq\n",
    "        #     total_timestep_1[query_count] = timestep_seq\n",
    "        # else:\n",
    "        #     total_reward_seq_2[query_count] = reward_seq\n",
    "        #     total_obs_seq_2[query_count] = obs_seq\n",
    "        #     total_next_obs_seq_2[query_count] = next_obs_seq\n",
    "        #     total_act_seq_2[query_count] = act_seq\n",
    "        #     total_timestep_2[query_count] = timestep_seq\n",
    "                \n",
    "        temp_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=.8\n",
    "use05=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent_list=['unrestricted','restricted']\n",
    "#unrestricted is agent 0, restricted is agent 1. Our restricted here is preferred, so agIdx=1 for preferred and 0 for not preferred#\n",
    "#this dataset is created assuming average pooling! No token prepended. \n",
    "#truncateGoalSteps=False (not truncating)\n",
    "datasetTorch={}\n",
    "for key in dataset:\n",
    "    datasetTorch[key]=torch.from_numpy(dataset[key])\n",
    "    \n",
    "def return_trajs(indices,preferredSuffix,notPreferredSuffix,max_len=1000):\n",
    "    prefObsKey,prefActionKey='observations'+preferredSuffix,'actions'+preferredSuffix\n",
    "    notPrefObsKey,notPrefActionKey='observations'+notPreferredSuffix,'actions'+notPreferredSuffix\n",
    "    prefObs, prefAction= datasetTorch[prefObsKey][indices], datasetTorch[prefActionKey][indices]\n",
    "    prefAgIdx=torch.zeros(prefObs.shape[:-1])+1\n",
    "    prefAgIdx=prefAgIdx.unsqueeze(2)\n",
    "\n",
    "    #taskIdPref=torch.zeros_like(prefAgIdx) #dummy task ID so it works in the existing capacity encoder framework \n",
    "\n",
    "    notPrefObs, notPrefAction= datasetTorch[notPrefObsKey][indices], datasetTorch[notPrefActionKey][indices]\n",
    "    notPrefAgIdx=torch.zeros_like(prefAgIdx)\n",
    "\n",
    "    #taskIdNotPref=torch.zeros_like(prefAgIdx) #dummy task ID so it works in the existing framework \n",
    "\n",
    "    maskShape=prefObs.shape[:-1]\n",
    "    src_key_padding_mask=torch.zeros(maskShape,dtype=torch.bool).unsqueeze(2) # assumed not truncating, so set to False. Both trajs use the same mask (all False anyway)\n",
    "\n",
    "    trajsPreferred=torch.cat([prefObs,prefAction,src_key_padding_mask, prefAgIdx],dim=2) #numTrajectories x stepMax(100) x obsDim+actionDim+3 (mask+agentId+taskId)\n",
    "    trajsNotPreferred=torch.cat([notPrefObs,notPrefAction,src_key_padding_mask,notPrefAgIdx],dim=2)\n",
    "\n",
    "    all_agent_trajectories=torch.cat([trajsPreferred,trajsNotPreferred],dim=0)\n",
    "    return all_agent_trajectories\n",
    "\n",
    "if use05:\n",
    "    indices10=np.union1d((dataset['labels']==[.5,.5]).all(axis=1).nonzero()[0], (dataset['labels']==[1,0]).all(axis=1).nonzero()[0]) #here we include both trajs where neither is preferred ([.5, .5]) in both agent types\n",
    "else:\n",
    "    indices10=(dataset['labels']==[1,0]).all(axis=1).nonzero()[0]\n",
    "trajs10=return_trajs(indices10,'','_2')\n",
    "\n",
    "indices01=(dataset['labels']==[0,1]).all(axis=1).nonzero()[0]# #here we only include the [0,1] indices. If we included [.5,.5] again we would double count indices. \n",
    "trajs01=return_trajs(indices01,'_2','')\n",
    "\n",
    "all_trajectories=torch.cat([trajs10,trajs01],dim=0)\n",
    "all_trajectories=all_trajectories[torch.randperm(all_trajectories.size()[0])]\n",
    "all_trajectories=all_trajectories.float()\n",
    "if train_size<1.0:\n",
    "    train_set, test_set = train_test_split(all_trajectories, train_size=train_size, shuffle=True)\n",
    "else:\n",
    "    train_set=all_trajectories\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 100, 16])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath='/home/srajaram/preference_videos/humanlabels/hopper-medium-expert-v2/train_set_with05.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/srajaram/preference_videos/humanlabels/hopper-medium-expert-v2/train_set_with05.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(train_set, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([160, 100, 16])\n",
      "torch.Size([40, 100, 16])\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape)\n",
    "print(test_set.shape)\n",
    "with open('/home/srajaram/preference_videos/humanlabels/hopper-medium-expert-v2/traintestsplit05/train_set_with05.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(train_set, f)\n",
    "with open('/home/srajaram/preference_videos/humanlabels/hopper-medium-expert-v2/traintestsplit05/test_set_with05.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(test_set, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([115, 100, 16])\n",
      "torch.Size([29, 100, 16])\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape)\n",
    "print(test_set.shape)\n",
    "with open('/home/srajaram/preference_videos/humanlabels/hopper-medium-expert-v2/traintestsplitNo05/train_set_No05.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(train_set, f)\n",
    "with open('/home/srajaram/preference_videos/humanlabels/hopper-medium-expert-v2/traintestsplitNo05/test_set_No05.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(test_set, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([494, 100, 16])\n",
      "torch.Size([124, 100, 16])\n"
     ]
    }
   ],
   "source": [
    "#hopper medium replay v2\n",
    "print(train_set.shape)\n",
    "print(test_set.shape)\n",
    "with open('/home/srajaram/preference_videos/humanlabels/hopper-medium-replay-v2/traintestsplitNo05/train_set_No05.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(train_set, f)\n",
    "with open('/home/srajaram/preference_videos/humanlabels/hopper-medium-replay-v2/traintestsplitNo05/test_set_No05.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(test_set, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Gym env render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########IMPORTED LOCALLY############\n",
      "######REGISTERING ENVIRONMENTS#####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/srajaram/')\n",
    "sys.path.append('/home/srajaram/rltransfer')\n",
    "sys.path.append('/home/srajaram/rltransfer/url_benchmark')\n",
    "import url_benchmark\n",
    "from url_benchmark.d4rl_benchmark import D4RLWrapper, D4RLReplayBufferBuilder\n",
    "from url_benchmark import dmc\n",
    "from url_benchmark.ContrastiveCapacityEncoderV2pbrl import PositionalEncoding, TransformerModel\n",
    "from collections import OrderedDict\n",
    "import gym\n",
    "import d4rl\n",
    "width=256\n",
    "height=256\n",
    "camera_name='track'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/srajaram/PreferenceTransformer/JaxPref'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9280089738242887"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gym_env.get_normalized_score(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srajaram/.local/lib/python3.10/site-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "gym_env = gym.make('hopper-medium-expert-v2')\n",
    "maxSc=gym_env.spec.kwargs['ref_max_score']\n",
    "minSc=gym_env.spec.kwargs['ref_min_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gym_env.spec.max_episode_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srajaram/.local/lib/python3.10/site-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "gym_env = gym.make('hopper-medium-expert-v2')\n",
    "gym_env.reset()\n",
    "curr_frame = gym_env.sim.render(width=width, height=height, mode=\"offscreen\", camera_name=camera_name)\n",
    "print(curr_frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUGMENT TIMESTEP\n",
      "ExtendedTimeStepD4RL(step_type=<StepType.FIRST: 0>, reward=None, discount=None, observation=array([ 1.25387213e+00, -2.76274593e-03,  1.72436865e-04, -1.10827922e-03,\n",
      "       -3.18006322e-03, -5.91725644e-04, -4.25065479e-03,  5.38520324e-04,\n",
      "       -2.26425940e-03,  2.45247530e-03,  1.72598181e-04]), physics=array(0.15), action=array([ 0.703257 ,  0.5275694, -0.969665 ], dtype=float32))\n",
      "True\n",
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "evalenv=dmc.EnvWrapper(D4RLWrapper(gym.make('hopper-medium-expert-v2')))\n",
    "\n",
    "evalenv.reset()\n",
    "\n",
    "frame=evalenv.base_env.base_env.sim.render(width=width, height=height, mode=\"offscreen\", camera_name=camera_name)\n",
    "print(frame.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Full Dataset for Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit convoluted but it makes things compatible with dmc so we don't run into issues later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srajaram/.local/lib/python3.10/site-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "gym_env = dmc.EnvWrapper(D4RLWrapper(gym.make('hopper-medium-expert-v2'))) ##make dmc compatible environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_fulloffline(gym_env): #This is a bit convoluted but it makes things compatible with dmc so we don't run into issues later\n",
    "    d4rl_replay_buffer_builder = D4RLReplayBufferBuilder() #use dmc function which creates ReplayBuffer\n",
    "    replay_storage = d4rl_replay_buffer_builder.prepare_replay_buffer_d4rl(gym_env, OrderedDict(), discount=.99, future=.99, minimum_episode_length=1, ignore_terminals=False)\n",
    "    actions=replay_storage._storage['action'].copy()\n",
    "    actions[:,:-1,:]=actions[:,1:,:] #deepmind control suite aligns the actions such that it pairs obs with the action that got you into obs. This is not the action that was taken in obs. Thus we shift accordingly such that obs is paired with action taken in obs\n",
    "    actions=torch.tensor(actions)\n",
    "    obs=torch.tensor(replay_storage._storage['observation'].copy())\n",
    "\n",
    "    maskShape=obs.shape[:-1]\n",
    "    epLens=torch.tensor(replay_storage._episodes_length.copy()).unsqueeze(1) #this is really the index of the last state, rather than the length (ie episode_length-1)\n",
    "    columns = torch.arange(maskShape[1]).unsqueeze(0)\n",
    "    src_key_padding_mask = columns >= epLens #this actually has the masking start one timestep before the last observation. This is because we don't have an action taken at the last observation, so the last timestep observed is not useable for encoding or decoding \n",
    "    src_key_padding_mask=src_key_padding_mask.unsqueeze(2)\n",
    "\n",
    "    batch_indices = torch.arange(maskShape[0])\n",
    "    obs[batch_indices, epLens.squeeze(), :]=0.0 #because the last obs doesn't have an action to go with it, set it equal to zero so that nothing weird when training model (ie it doesn't try to map the last obs to doing nothing). Of course, the src_key_padding_mask should take care of this, but just to be on the safe side \n",
    "\n",
    "    datasetNew=torch.cat([obs,actions,src_key_padding_mask],dim=2)\n",
    "    return datasetNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load datafile: 100%|██████████| 9/9 [00:03<00:00,  2.96it/s]\n"
     ]
    }
   ],
   "source": [
    "ds=create_dataset_fulloffline(gym_env)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath='/home/srajaram/preference_videos/hopper-medium-expert-v2/fulldataset.pkl'\n",
    "with open(filepath, 'wb') as f:  # open a text file\n",
    "    pickle.dump(ds, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offline RL Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/srajaram/')\n",
    "sys.path.append('/home/srajaram/rltransfer')\n",
    "sys.path.append('/home/srajaram/rltransfer/url_benchmark')\n",
    "sys.path.append('/home/srajaram/rltransfer/OfflineRL-Kit')\n",
    "import url_benchmark\n",
    "from url_benchmark.pbrl.CottonDecoderV2pbrl import TransformerForInference\n",
    "from collections import OrderedDict\n",
    "\n",
    "import gym\n",
    "import d4rl\n",
    "\n",
    "import offlinerlkit\n",
    "from offlinerlkit.nets import MLP\n",
    "from offlinerlkit.modules import ActorProb, Critic, TanhDiagGaussian\n",
    "from offlinerlkit.utils.load_dataset import qlearning_dataset\n",
    "from offlinerlkit.buffer import ReplayBuffer\n",
    "from offlinerlkit.utils.logger import Logger, make_log_dirs\n",
    "from offlinerlkit.policy_trainer import MFPolicyTrainer\n",
    "from offlinerlkit.policy import CQLPolicy\n",
    "\n",
    "import PreferenceTransformer\n",
    "from PreferenceTransformer.dataset_utils import split_into_trajectories    \n",
    "from tqdm import tqdm, trange\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srajaram/.local/lib/python3.10/site-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "load datafile: 100%|██████████| 11/11 [00:00<00:00, 36.91it/s]\n",
      "split: 100%|██████████| 401598/401598 [00:00<00:00, 604119.71it/s]\n"
     ]
    }
   ],
   "source": [
    "task='hopper-medium-replay-v2'\n",
    "env = gym.make(task)\n",
    "eps= 1e-5\n",
    "clip_to_eps=True\n",
    "dataset = d4rl.qlearning_dataset(env)\n",
    "\n",
    "if clip_to_eps:\n",
    "    lim = 1 - eps\n",
    "    dataset['actions'] = np.clip(dataset['actions'], -lim, lim)\n",
    "\n",
    "dones_float = np.zeros_like(dataset['rewards'])\n",
    "\n",
    "for i in range(len(dones_float) - 1):\n",
    "    if np.linalg.norm(dataset['observations'][i + 1] -\n",
    "                        dataset['next_observations'][i]\n",
    "                        ) > 1e-5 or dataset['terminals'][i] == 1.0:\n",
    "        dones_float[i] = 1\n",
    "    else:\n",
    "        dones_float[i] = 0\n",
    "\n",
    "dones_float[-1] = 1\n",
    "dataset['observations']=dataset['observations'].astype(np.float32)\n",
    "dataset['actions']=dataset['actions'].astype(np.float32)\n",
    "dataset['rewards']=dataset['rewards'].astype(np.float32)\n",
    "dataset['masks']=1.0-dataset['terminals'].astype(np.float32)\n",
    "dataset['terminals']=dones_float.astype(np.float32)\n",
    "dataset['next_observations']=dataset['next_observations'].astype(\n",
    "                        np.float32)\n",
    "\n",
    "trajs = split_into_trajectories(\n",
    "    dataset['observations'],\n",
    "    dataset['actions'],\n",
    "    dataset['rewards'],\n",
    "    dataset['masks'], #masks\n",
    "    dataset['terminals'],\n",
    "    dataset['next_observations']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk trajectories:   0%|          | 0/2039 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk trajectories: 100%|██████████| 2039/2039 [00:06<00:00, 298.49it/s]\n"
     ]
    }
   ],
   "source": [
    "max_ep_len=1000\n",
    "obsDim=dataset['observations'].shape[1]\n",
    "actionDim=dataset['actions'].shape[1]\n",
    "dataForEncoder = torch.zeros((len(trajs),max_ep_len,obsDim+actionDim+1)) #the +1 is for the mask \n",
    "dataset_idx_mapper = torch.zeros(len(trajs),max_ep_len)\n",
    "\n",
    "dataset_idx=0\n",
    "for trj_idx, traj in tqdm(enumerate(trajs), total=len(trajs), desc=\"chunk trajectories\"):\n",
    "    _obs=torch.zeros((len(traj),obsDim))\n",
    "    _action=torch.zeros((len(traj),actionDim))\n",
    "    \n",
    "    for stepIdx,transitionTuple in enumerate(traj):\n",
    "        _o, _a, _r, _m, _d, _no=transitionTuple\n",
    "        _obs[stepIdx,:]=torch.tensor(_o)\n",
    "        _action[stepIdx,:]=torch.tensor(_a)\n",
    "        dataset_idx_mapper[trj_idx,stepIdx]=dataset_idx #need this to go back to the buffer of transitions\n",
    "        dataset_idx+=1\n",
    "    \n",
    "    epLen=_obs.shape[0]\n",
    "    dataForEncoder[trj_idx,:epLen,:obsDim]=_obs\n",
    "    dataForEncoder[trj_idx,:epLen,obsDim:obsDim+actionDim]=_action\n",
    "    #src key padding mask: 0s where we have real data, 1 from onwards\n",
    "    maskCol=dataForEncoder[trj_idx,:epLen,-1]\n",
    "    columns = torch.arange(max_ep_len)\n",
    "    src_key_padding_maskCol = columns >= epLen \n",
    "    dataForEncoder[trj_idx,:,-1]=src_key_padding_maskCol\n",
    "    ######################\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You should use a capacity encoder model that was trained on the full dataset (so there should be no test set)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m     test_set \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(test_set)\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should use a capacity encoder model that was trained on the full dataset (so there should be no test set)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: You should use a capacity encoder model that was trained on the full dataset (so there should be no test set)"
     ]
    }
   ],
   "source": [
    "cfg={}\n",
    "cfg['causal_pool1']=True\n",
    "cfg['causal_pool2']=False\n",
    "cfg['alpha']=.01\n",
    "cfg['beta']=.02\n",
    "capacityEncoderFilepath='/home/srajaram/rltransfer/exp_local/2025.02.01/_HopperMediumReplayCapacityNo05_smallerdims/103727'\n",
    "with open(os.path.join(capacityEncoderFilepath,'cfg.pkl'), 'rb') as f:\n",
    "    capEncCfg = pickle.load(f) \n",
    "   \n",
    "\n",
    "capacity_inference=TransformerForInference(capEncCfg, causal_pool1=cfg['causal_pool1'],causal_pool2=cfg['causal_pool2'])\n",
    "capacity_inference.eval()\n",
    "\n",
    "with open(os.path.join(capacityEncoderFilepath,'train_set.pkl'), 'rb') as f:\n",
    "    train_set = pickle.load(f)\n",
    "trainDataloader=DataLoader(train_set, batch_size=256, shuffle=False) #creating dataloader only because the relevant function (getEvalLatents) requires it as input, but will just be using the full dataset in that function\n",
    "with open(os.path.join(capacityEncoderFilepath,'test_set.pkl'), 'rb') as f:\n",
    "    test_set = pickle.load(f)\n",
    "if len(test_set)!=0:\n",
    "    raise ValueError(\"You should use a capacity encoder model that was trained on the full dataset (so there should be no test set)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataForCapacity=dataForEncoder[:,:,:capacity_inference.inputDim] #needed for the capacity latent inference, not distinguishing by agent type\n",
    "actions=dataForEncoder[:,:,obsDim:obsDim+actionDim] #used for decoder loss\n",
    "mask=dataForEncoder[:,:,obsDim+actionDim] #padding mask, needed for both the decoder loss and the capacity latent inference \n",
    "\n",
    "capacityLatents=capacity_inference.forward(dataForCapacity, src_key_padding_mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######Using preloaded train/test sets#######\n"
     ]
    }
   ],
   "source": [
    "#get fixed latents from the two classes of agents (preferred and not preferred)\n",
    "capacityEncoder=url_benchmark.ContrastiveCapacityEncoderV2pbrl.CapacityEncoderV2(capEncCfg,'',train_set=train_set,test_set=[],use_wandb=False) #the train set and test set must be passed in to initialize the class but we don't use it here. \n",
    "capacityEncoder.capacity_encoder.load_state_dict(torch.load(os.path.join(capacityEncoderFilepath,'capacityEncoder.pt'), weights_only=True))\n",
    "capacityEncoder.capacity_encoder.eval()\n",
    "capacityEncoder=capacityEncoder\n",
    "allAgentLatents={} #only used in policy eval rollouts\n",
    "for i in range(len(capacityEncoder.agent_list)):\n",
    "    latents=capacityEncoder.getEvalLatents(i,trainDataloader).clone().detach()\n",
    "    if i==0:\n",
    "        agent='unpreferred'\n",
    "    if i==1:\n",
    "        agent='preferred'\n",
    "    allAgentLatents[agent]=latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos=torch.nn.CosineSimilarity(dim=2)\n",
    "simWUnpreferred=cos(capacityLatents,allAgentLatents['unpreferred'].repeat(max_ep_len,1))\n",
    "simWPreferred=cos(capacityLatents,allAgentLatents['preferred'].repeat(max_ep_len,1)) \n",
    "new_rewards=cfg['alpha']*simWPreferred-cfg['beta']*simWUnpreferred\n",
    "new_rewards=new_rewards.detach().numpy() #shape number of trajectories, max_ep_len, this will include rewards for timesteps of a trajectory that were padded on. But we'll take care of that in rematching to the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The above was pulled together into the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('/home/srajaram/rltransfer/exp_local/2025.02.06/HopperMediumReplayCapacityOfflineDataset','offline_dataset_modifiedreward.pkl'), 'rb') as f:\n",
    "    offlinedataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########IMPORTED LOCALLY############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######REGISTERING ENVIRONMENTS#####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/glfw/__init__.py:917: GLFWError: (65550) b'X11: The DISPLAY environment variable is missing'\n",
      "  warnings.warn(message, GLFWError)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/user/rajaram/u13657/rltransfer')\n",
    "import url_benchmark\n",
    "from url_benchmark.pbrl.make_offlinedataset import make_offline_dataset\n",
    "import os\n",
    "import pickle\n",
    "import url_benchmark\n",
    "from url_benchmark.pbrl.CottonDecoderV2pbrl import TransformerForInference\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.19817598, -0.98015704, -1.87695922, ..., -0.13831469,\n",
       "        0.66657294,  0.21992515])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['rewards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.19817601, -0.98015707, -1.87695932, ..., -0.1383147 ,\n",
       "        0.66657295,  0.21992514])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetLowRew['rewards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7676622322017877e-08\n",
      "1.8516079241829727e-08\n"
     ]
    }
   ],
   "source": [
    "absolute_differences = np.abs(dataset['rewards'] - datasetLowRew['rewards'])\n",
    "\n",
    "mean_diff = np.mean(absolute_differences)\n",
    "std_diff = np.std(absolute_differences)\n",
    "print(mean_diff)\n",
    "print(std_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 51550, 124416, 148449, 194485, 224855, 229099, 230182, 333364]),)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.round(dataset['rewards'],3)!=np.round(datasetLowRew['rewards'],3)).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.071\n",
      "-1.071499970303982\n"
     ]
    }
   ],
   "source": [
    "print(np.round(dataset['rewards'],3)[51550])\n",
    "print(dataset['rewards'][51550])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.072\n",
      "-1.0715000142157831\n"
     ]
    }
   ],
   "source": [
    "print(np.round(datasetLowRew['rewards'],3)[51550])\n",
    "print(datasetLowRew['rewards'][51550])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4900522412961353e-08\n",
      "4.9899801980514895e-06\n"
     ]
    }
   ],
   "source": [
    "dataset_clipped = np.floor(dataset['rewards'] * 1e3) / 1e3\n",
    "datasetLowRew_clipped = np.floor(datasetLowRew['rewards'] * 1e3) / 1e3\n",
    "absolute_differences = np.abs(dataset_clipped - datasetLowRew_clipped)\n",
    "\n",
    "mean_diff = np.mean(absolute_differences)\n",
    "std_diff = np.std(absolute_differences)\n",
    "print(mean_diff)\n",
    "print(std_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/rajaram/u13657/.local/lib/python3.10/site-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "load datafile: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 25.43it/s]\n",
      "split: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 401598/401598 [00:01<00:00, 398855.28it/s]\n",
      "chunk trajectories: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 2039/2039 [00:08<00:00, 250.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######Using preloaded train/test sets#######\n",
      "Input train set size 494 and test set size is 0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "split: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 401598/401598 [00:01<00:00, 311086.59it/s]\n",
      "chunk trajectories: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 2039/2039 [00:00<00:00, 52689.79it/s]\n"
     ]
    }
   ],
   "source": [
    "cfg={'capacityEncoderFilepath':os.path.join(os.path.expanduser('~'),'rltransfer/exp_local/2025.02.01/_HopperMediumReplayCapacityNo05_smallerdims/103727'), 'task':'hopper-medium-replay-v2', 'max_ep_len':1000}\n",
    "cfg['causal_pool1']=False\n",
    "cfg['causal_pool2']=False\n",
    "cfg['alpha']=.1\n",
    "cfg['beta']=0.0\n",
    "datasetLowRew=make_offline_dataset(cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonPbrl",
   "language": "python",
   "name": "container_python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
